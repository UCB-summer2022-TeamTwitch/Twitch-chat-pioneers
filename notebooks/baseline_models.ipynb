{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/Vaibhav_Beohar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import string\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our dataset\n",
    "df_yelp = pd.read_table('../data/external/yelp_labelled.txt')\n",
    "df_imdb = pd.read_table('../data/external/imdb_labelled.txt')\n",
    "df_amz = pd.read_table('../data/external/amazon_cells_labelled.txt')\n",
    "\n",
    "# utilizing code from https://monstott.github.io/sentiment_analysis_and_classification_of_amazon_imdb_and_yelp_reviews\n",
    "# and https://www.section.io/engineering-education/sentiment-analysis-with-spacy-and-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate our Datasets\n",
    "frames = [df_yelp,df_imdb,df_amz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming Column Headers\n",
    "for colname in frames:\n",
    "    colname.columns = [\"Message\",\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Column names\n",
    "# for colname in frames:\n",
    "#     print(colname.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assign a Key to Make it Easier\n",
    "# keys = ['Yelp','IMDB','Amazon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge or Concat our Datasets\n",
    "# df = pd.concat(frames,keys=keys)\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Now I am getting angry and I want my damn pho.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message  Target\n",
       "0                                 Crust is not good.       0\n",
       "1          Not tasty and the texture was just nasty.       0\n",
       "2  Stopped by during the late May bank holiday of...       1\n",
       "3  The selection on the menu was great and so wer...       1\n",
       "4     Now I am getting angry and I want my damn pho.       0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# train-test split\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(df.Message, df.Target) \n",
    "\n",
    "# label encode the target \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count vector\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}') \n",
    "count_vect.fit(df.Message) # regexp selects tokens of 1 or more alphanumeric characters\n",
    "\n",
    "xall_count = count_vect.transform(df.Message)\n",
    "xtrain_count = count_vect.transform(x_train)\n",
    "xtest_count = count_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "549    I really do recommend this place, you can go w...\n",
       "951    The ambiance here did not feel like a buffet s...\n",
       "580             None of them are engaging or exciting.  \n",
       "627    I asked multiple times for the wine list and a...\n",
       "421    This is a masterful piece of film-making, with...\n",
       "                             ...                        \n",
       "826    For that price I can think of a few place I wo...\n",
       "916                  Leopard Print is wonderfully wild!.\n",
       "409            And the accents are absolutely abysmal!  \n",
       "484                   A good film by a great director!  \n",
       "573    Our server was super nice and checked on us ma...\n",
       "Name: Message, Length: 2058, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xtrain_count\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tf-idf\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# # word-level tf-idf\n",
    "# tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "# tfidf_vect.fit(df.Message)\n",
    "# xtrain_tfidf = tfidf_vect.transform(x_train)\n",
    "# xtest_tfidf = tfidf_vect.transform(x_test)\n",
    "\n",
    "# # ngram-level tf-idf \n",
    "# tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2, 3), max_features=5000)\n",
    "# tfidf_vect_ngram.fit(df.Message) # measures bi-grams and tri-grams\n",
    "# xtrain_tfidf_ngram = tfidf_vect_ngram.transform(x_train)\n",
    "# xtest_tfidf_ngram = tfidf_vect_ngram.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model wrapper function\n",
    "from sklearn import metrics\n",
    "\n",
    "def train_model(classifier, train_features, label, test_features):\n",
    "    # fit the training data on classifier\n",
    "    classifier.fit(train_features, label)\n",
    "    \n",
    "    # predict testing data labels\n",
    "    predictions = classifier.predict(test_features)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Naive Bayes] Count Vectors Accuracy: 0.833\n",
      "[Naive Bayes] Word-Level TF-IDF Accuracy: 0.491\n",
      "[Naive Bayes] N-Gram-Level TF-IDF Accuracy: 0.466\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "# Count Vectors\n",
    "nb_cv = train_model(naive_bayes.MultinomialNB(), xtrain_count, y_train, xtest_count)\n",
    "print(\"[Naive Bayes] Count Vectors Accuracy:\", round(nb_cv, 3))\n",
    "\n",
    "# Word-Level TF-IDF Vectors\n",
    "nb_wl = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print(\"[Naive Bayes] Word-Level TF-IDF Accuracy:\", round(nb_wl, 3))\n",
    "\n",
    "# Ngram-Level TF-IDF Vectors\n",
    "nb_nl = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, y_train, xtest_tfidf_ngram)\n",
    "print(\"[Naive Bayes] N-Gram-Level TF-IDF Accuracy:\", round(nb_nl, 3))\n",
    "\n",
    "# > [Naive Bayes] Count Vectors Accuracy: 0.819\n",
    "# > [Naive Bayes] Word-Level TF-IDF Accuracy: 0.809\n",
    "# > [Naive Bayes] N-Gram-Level TF-IDF Accuracy: 0.663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Logistic Regression] Count Vectors Accuracy: 0.841\n",
      "[Logistic Regression] Word-Level TF-IDF Accuracy: 0.483\n",
      "[Logistic Regression] N-Gram TF-IDF Accuracy: 0.451\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Count Vectors\n",
    "lr_cv = train_model(linear_model.LogisticRegression(), xtrain_count, y_train, xtest_count)\n",
    "print(\"[Logistic Regression] Count Vectors Accuracy:\", round(lr_cv, 3))\n",
    "\n",
    "# Word-Level TF-IDF Vectors\n",
    "lr_wl = train_model(linear_model.LogisticRegression(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print(\"[Logistic Regression] Word-Level TF-IDF Accuracy:\", round(lr_wl, 3))\n",
    "\n",
    "# Ngram-Level TF-IDF Vectors\n",
    "lr_nl = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, y_train, xtest_tfidf_ngram)\n",
    "print(\"[Logistic Regression] N-Gram TF-IDF Accuracy:\", round(lr_nl, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Support Vector Machines] Count Vectors Accuracy: 0.801\n",
      "[Support Vector Machines] Word-Level TF-IDF Accuracy: 0.479\n",
      "[Support Vector Machines] N-Gram TF-IDF Accuracy: 0.472\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "from sklearn import svm\n",
    "\n",
    "# Count Vectors\n",
    "svm_cv = train_model(svm.SVC(), xtrain_count, y_train, xtest_count)\n",
    "print(\"[Support Vector Machines] Count Vectors Accuracy:\", round(svm_cv, 3))\n",
    "\n",
    "# Word-Level TF-IDF Vectors\n",
    "svm_wl = train_model(svm.SVC(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print(\"[Support Vector Machines] Word-Level TF-IDF Accuracy:\", round(svm_wl, 3))\n",
    "\n",
    "# Ngram-Level TF-IDF Vectors\n",
    "svm_nl = train_model(svm.SVC(), xtrain_tfidf_ngram, y_train, xtest_tfidf_ngram)\n",
    "print(\"[Support Vector Machines] N-Gram TF-IDF Accuracy:\", round(svm_nl, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Random Forest] Count Vectors Accuracy: 0.803\n",
      "[Random Forest] Word-Level TF-IDF Accuracy: 0.463\n",
      "[Random Forest] N-Gram TF-IDF Accuracy: 0.483\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn import ensemble\n",
    "\n",
    "# Count Vectors\n",
    "rf_cv = train_model(ensemble.RandomForestClassifier(), xtrain_count, y_train, xtest_count)\n",
    "print(\"[Random Forest] Count Vectors Accuracy:\", round(rf_cv, 3))\n",
    "\n",
    "# Word-Level TF-IDF Vectors\n",
    "rf_wl = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print(\"[Random Forest] Word-Level TF-IDF Accuracy:\", round(rf_wl, 3))\n",
    "\n",
    "# Ngram-Level TF-IDF Vectors\n",
    "rf_nl = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram, y_train, xtest_tfidf_ngram)\n",
    "print(\"[Random Forest] N-Gram TF-IDF Accuracy:\", round(rf_nl, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Xtreme Gradient Boosting] Count Vectors Accuracy: 0.776\n",
      "[Xtreme Gradient Boosting] Word-Level TF-IDF:  0.485\n",
      "[Xtreme Gradient Boosting] N-Gram TF-IDF Accuracy: 0.496\n"
     ]
    }
   ],
   "source": [
    "# Extreme Gradient Boosting\n",
    "import xgboost\n",
    "\n",
    "# Count Vectors\n",
    "xgb_cv = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), y_train, xtest_count.tocsc())\n",
    "print(\"[Xtreme Gradient Boosting] Count Vectors Accuracy:\", round(xgb_cv, 3))\n",
    "\n",
    "# Word-Level TF-IDF Vectors\n",
    "xgb_wl = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), y_train, xtest_tfidf.tocsc())\n",
    "print(\"[Xtreme Gradient Boosting] Word-Level TF-IDF: \", round(xgb_wl, 3))\n",
    "\n",
    "# Ngram-Level TF-IDF Vectors\n",
    "xgb_nl = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram, y_train, xtest_tfidf_ngram)\n",
    "print(\"[Xtreme Gradient Boosting] N-Gram TF-IDF Accuracy:\", round(xgb_nl, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count Vector</th>\n",
       "      <th>Word TF-IDF</th>\n",
       "      <th>n-Gram TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xtreme Gradient Boosting</th>\n",
       "      <td>0.776</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Count Vector  Word TF-IDF  n-Gram TF-IDF\n",
       "Naive Bayes                      0.833        0.491          0.466\n",
       "Logistic Regression              0.841        0.483          0.451\n",
       "Support Vector Machines          0.801        0.479          0.472\n",
       "Random Forest                    0.803        0.463          0.483\n",
       "Xtreme Gradient Boosting         0.776        0.485          0.496"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model performance table\n",
    "pd.DataFrame([[nb_cv, nb_wl, nb_nl],\n",
    "              [lr_cv, lr_wl, lr_nl],\n",
    "              [svm_cv, svm_wl, svm_nl],\n",
    "              [rf_cv, rf_wl, rf_nl],\n",
    "              [xgb_cv, xgb_wl, xgb_nl]], \n",
    "columns=['Count Vector', 'Word TF-IDF', 'n-Gram TF-IDF'], \n",
    "index=['Naive Bayes', 'Logistic Regression', 'Support Vector Machines', 'Random Forest', 'Xtreme Gradient Boosting']).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "nb_model = naive_bayes.MultinomialNB()\n",
    "nb_model.fit(xtrain_count, y_train)\n",
    "print(nb_model.predict(count_vect.transform(pd.Series('POG: indicate excitement, an epic moment'))))\n",
    "print(nb_model.predict(count_vect.transform(pd.Series('I feel horrible'))))\n",
    "print(nb_model.predict(count_vect.transform(pd.Series('KEKW: it suggests laughter'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
