{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ee4cf6-89ef-42b6-bef0-f2e6ef974c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at veb/twitch-bert-base-cased-pytorch were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at veb/twitch-bert-base-cased-pytorch and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from twitch_listener import utils\n",
    "from twitch_listener import listener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "112c4760-2019-48f4-a532-6160ff047a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Twitch\n",
    "# bot = listener.connect_twitch('twitch_pioneers', \n",
    "#                              'oauth:lolbsmiac5expvax1iqiysfo18hqi2', \n",
    "#                              '6resxnu2ehi2ggn0kgpue6g12bxtlw',\n",
    "#                              'zkekfhyhzhdl8ltxs6b8jdez7b2i6b')\n",
    "\n",
    "nickname = 'twitch_pioneers'\n",
    "oauth_chat = 'oauth:lolbsmiac5expvax1iqiysfo18hqi2'\n",
    "client_id = '6resxnu2ehi2ggn0kgpue6g12bxtlw'\n",
    "oauth_api = 'Bearer y5o8h4s2fljc1s632ylfrb540npcs0'\n",
    "\n",
    "\n",
    "bot = listener.connect_twitch(nickname, \n",
    "                             oauth_chat, \n",
    "                             client_id,\n",
    "                             oauth_api)\n",
    "\n",
    "chat_file_path = '/home/w210/Twitch-chat-pioneers/chat_listener'\n",
    "\n",
    "# List of channels to connect to\n",
    "# Channel names must be lowercase\n",
    "channels_to_listen_to = ['cryocells','jingggxd','gmhikaru','lirik']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93212d1c-1efd-4b9f-8b13-b172f6b015fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cryocells': '432532052', 'jingggxd': '136397315'}\n"
     ]
    }
   ],
   "source": [
    "#returns list of live channels\n",
    "channels_to_listen_to = utils.is_live(channels_to_listen_to)\n",
    "\n",
    "channels_to_listen_to = utils.get_broadcast_id(channels_to_listen_to, client_id, oauth_api)\n",
    "print(channels_to_listen_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd363617-e6af-4571-98f2-e234eecf16b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels Offline\n"
     ]
    }
   ],
   "source": [
    "# Scrape live chat data into raw log files. (Duration is seconds)\n",
    "bot.listen(channels_to_listen_to, duration = 30, until_offline = True, debug = False) \n",
    "\n",
    "# Convert log files into .CSV format\n",
    "#bot.parse_logs(timestamp = True, file_path = chat_file_path)\n",
    "\n",
    "# Generate adjacency matrix\n",
    "#bot.adj_matrix(weighted = False, matrix_name = \"streamer_network.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3618b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/w210/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Pass to function\n",
    "from load_sentiment_model import load_model\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import sqlite3\n",
    "\n",
    "PRE_TRAINED_MODEL_NAME = \"veb/twitch-bert-base-cased-pytorch\" #'models/veb/twitch-bert-base-cased-finetuned'\n",
    "MAX_LEN = 160\n",
    "class_names = ['negative', 'neutral', 'positive']\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "model = load_model()\n",
    "conn = sqlite3.connect('/home/w210/Twitch-chat-pioneers/src/front_end/db.sqlite3')\n",
    "cursor_obj = conn.cursor()\n",
    "cursor_obj.execute(\"\"\"select username, channel_name, date, message_text from chats_table_demo\n",
    "                    where message_sentiment is NULL \"\"\")\n",
    "output = cursor_obj.fetchall()\n",
    "for review_text in output:\n",
    "    #Get sentiment for each message\n",
    "    sentiment = utils.message_sentiment(review_text[3],\n",
    "                                  tokenizer,\n",
    "                                  model, \n",
    "                                  class_names, \n",
    "                                  PRE_TRAINED_MODEL_NAME,MAX_LEN = 160)\n",
    "    #Update table with sentiments\n",
    "    cursor_obj.execute(\"\"\"UPDATE chats_table_demo\n",
    "                        SET message_sentiment = {}\n",
    "                        WHERE username = {} and \n",
    "                        channel_name = {} and\n",
    "                        date = {};\"\"\".format(sentiment,\n",
    "                                                \"\\'\" + review_text[0] + \"\\'\",\n",
    "                                                 \"\\'\" + review_text[1] + \"\\'\",\n",
    "                                                 \"\\'\" + review_text[2] + \"\\'\" ))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "438f7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d40d6ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a2guapo', 'VALORANT', 146, 15),\n",
       " ('cryocells', 'VALORANT', 665, 39),\n",
       " ('faide', 'Apex Legends', 951, 18),\n",
       " ('gmhikaru', 'Just Chatting', 683, 169),\n",
       " ('jingggxd', 'VALORANT', 1351, 58),\n",
       " ('lirik', 'Evolve Stage 2', 7426, 178),\n",
       " ('lirik', 'Just Chatting', 31576, 98),\n",
       " ('nats', 'VALORANT', 293, 23),\n",
       " ('shivfps', 'Apex Legends', 3033, 174),\n",
       " ('sweetdreams', 'Apex Legends', 3414, 177),\n",
       " ('xeppaa', 'VALORANT', 275, 7)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test = conn.execute('''drop table if exists chats_table_demo''')\n",
    "#test = conn.execute('''create table chats_table_test as select * from chats_table_sentiment limit 100''')\n",
    "conn = sqlite3.connect('/home/w210/Twitch-chat-pioneers/src/front_end/db.sqlite3')\n",
    "test = conn.execute('''select channel_name,stream_topic,  count(*), max(stream_length) from chats_table_demo group by channel_name, stream_topic''')\n",
    "output = test.fetchall()\n",
    "conn.close()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a985a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amouranth',\n",
       "  'ð\\x9f\\x8d\\x91BIKINI MOIST MONDAYSð\\x9f\\x92¦ type !s for my social media',\n",
       "  'Pools, Hot Tubs, and Beaches'),\n",
       " ('tarik', 'BACK ON IT | Twitter @tarik', 'VALORANT'),\n",
       " ('iitztimmy',\n",
       "  'Practicing for Rivals // Follow my socials @iiTzTimmy',\n",
       "  'Apex Legends'),\n",
       " ('nickmercs',\n",
       "  \"Warzone Fraggin' | Code: MFAM | @NICKMERCS\",\n",
       "  'Call of Duty: Warzone'),\n",
       " ('iitztimmy', 'apexge // Follow my socials @iiTzTimmy', 'Apex Legends'),\n",
       " ('nickmercs', 'Hibernating | Code: MFAM | @NICKMERCS', 'Apex Legends')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect('/home/w210/Twitch-chat-pioneers/src/front_end/db.sqlite3')\n",
    "test = conn.execute('''select channel_name,  count(*) from chats_table_demo group by channel_name ''')\n",
    "output = test.fetchall()\n",
    "conn.close()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "615b63ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(28, 9235.285714285714, 73285.5),\n",
       " (21, 9521.142857142857, 71950.85714285714),\n",
       " (101, 20006.465346534653, 26255.48514851485)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = conn.execute('''select count(*) as messages, \n",
    "                        avg(viewer_count) as avg_viewers,\n",
    "                        avg(subscriber_count) as avg_subscribers\n",
    "                        from chats_table\n",
    "                        group by channel_name, stream_topic, stream_date\n",
    "                        ''')\n",
    "test.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a042ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSERT INTO chats_table(\n",
    "                                          date, \n",
    "                                          stream_date,\n",
    "                                          stream_length,\n",
    "                                          username, \n",
    "                                          message_text, \n",
    "                                          channel_name,\n",
    "                                          stream_topic,\n",
    "                                          stream_title,\n",
    "                                          chatter_count,\n",
    "                                          viewer_count,\n",
    "                                          follower_count,\n",
    "                                          subscriber_count,\n",
    "                                          stream_id,\n",
    "                                         avg_sentiment"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
